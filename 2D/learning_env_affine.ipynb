{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from scipy.special import gammaln\n",
    "import torch\n",
    "\n",
    "import scipy.stats as stats\n",
    "import train_2D_rt_v2 as tr\n",
    "import tools_2D_rt_v2 as tt\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data\n",
    "\n",
    "\n",
    "Make sure you have also copied '/home/mcarilli/CME/2D_CME/learning_environment/train_2D_rt_v1.py' and\n",
    "'/home/mcarilli/CME/2D_CME/learning_environment/tools_2D_rt_v1.py' to your file location. \n",
    "\n",
    "\n",
    "If you want to load in pre-generated data, there are 20 batches of 5,120 are already stored in:\n",
    "\n",
    "\n",
    "1. '/home/mcarilli/CME/2D_CME/learning_environment/training_data_quadvec/'\n",
    "2. '/home/mcarilli/CME/2D_CME/learning_environment/training_data_fixedquad/'\n",
    "\n",
    "\n",
    "There are also 10 batches of 512 parameters in 1 (_fixedquad/_) and 10 batches of 256 parameterc in 2 (_quadvec/_). \n",
    "generated using quad_vec and fixed_quad, respectively. \n",
    "\n",
    "\n",
    "If you want to make and store other data files, here is some code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your data path\n",
    "\n",
    "path =  './training_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_size = 256\n",
    "num_files = 10\n",
    "N = num_files*set_size\n",
    "\n",
    "\n",
    "params = tr.generate_param_vectors(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your xmax function!! \n",
    "\n",
    "def xmax_fun(xmax):\n",
    "\n",
    "    return(4.5*xmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_sets(set_size,num_files,param_vectors,method,xmax_fun,NCOR,path_to_directory)\n",
    "tr.generate_sets_pcme(set_size = 256,num_files=num_files,param_vectors = params,\n",
    "                 method = 'quad_vec',\n",
    "                 xmax_fun=xmax_fun,\n",
    "                 NCOR = 60,\n",
    "                 path_to_directory=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ! \n",
    "\n",
    "\n",
    "Here are the generating grid and get_ypred_at_RT functions! \n",
    "\n",
    "\n",
    "You can choose to generate the grid using NORM_nas, NORM_mat quantiles (linear right now, rectangular grid), or performin an affine transform with the covariance matrix and means. \n",
    "\n",
    "To change, merely change the generate_grid function in get_ypred_at_RT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grid(npdf,VAR,MU,p,quantiles=None):\n",
    "    \n",
    "    if quantiles=='PRESET':\n",
    "        logstd = torch.sqrt(torch.log((VAR/MU**2)+1))\n",
    "        logmean = torch.log(MU**2/torch.sqrt(VAR+MU**2))\n",
    "        translin_0 = torch.exp(logmean[0]+logstd[0]*NORM_nas)\n",
    "        translin_1 = torch.exp(logmean[1]+logstd[1]*NORM_mat)\n",
    "        \n",
    "        \n",
    "        GRID_nas,GRID_mat = torch.meshgrid(translin_0,translin_1,indexing='ij')\n",
    "        \n",
    "        return GRID_nas,GRID_mat\n",
    "\n",
    "    \n",
    "# def generate_grid_affine(npdf,VAR,MU,p,quantiles=None):\n",
    "    \n",
    "#     if quantiles=='PRESET':\n",
    "#         logstd = torch.sqrt(torch.log((VAR/MU**2)+1))\n",
    "#         logvar = logstd**2\n",
    "#         logmean = torch.log(MU**2/torch.sqrt(VAR+MU**2))\n",
    "        \n",
    "#         # calculate sigma_ij\n",
    "#         var_ij = p[0]**2/ (p[1]+p[2]) \n",
    "#         logst_ij = torch.log( var_ij * np.exp(-(logmean.sum()+logvar.sum()/2)) +1 )\n",
    "\n",
    "#         sig_ii = logvar[0]\n",
    "#         sig_jj = logvar[1]\n",
    "#         sig_ij = logst_ij\n",
    "        \n",
    "#         xv, yv = torch.meshgrid(NORM_nas,NORM_mat,indexing='ij')\n",
    "        \n",
    "#         Sig = torch.tensor([[sig_ii,sig_ij],[sig_ij,sig_jj]])\n",
    "#         A = torch.linalg.cholesky(Sig,upper=False)\n",
    "\n",
    "   \n",
    "#         GRID_nas = torch.exp(A[0,0]*xv+A[1,0]*yv + logmean[0])\n",
    "#         GRID_mat = torch.exp(A[0,1]*xv+A[1,1]*yv + logmean[1])\n",
    "        \n",
    "#         return GRID_nas,GRID_mat\n",
    "\n",
    "\n",
    "\n",
    "def generate_grid_affine(npdf,VAR,MU,p,quantiles=None):\n",
    "    if quantiles=='PRESET':\n",
    "        logvar = torch.log((VAR/MU**2)+1)\n",
    "        logmean = torch.log(MU**2/torch.sqrt(VAR+MU**2))\n",
    "\n",
    "        var_ij = p[0]**2/ (p[1]+p[2]) \n",
    "        logst_ij = torch.log( var_ij * np.exp(-(logmean.sum()+logvar.sum()/2)) +1 ) #set this to zero if you want to \n",
    "        #just use a grid with zero correlation\n",
    "        \n",
    "        xv, yv = torch.meshgrid(NORM_nas,NORM_mat,indexing='ij')\n",
    "\n",
    "        a = torch.sqrt(logvar[0])\n",
    "        b = logst_ij/a\n",
    "        c = torch.sqrt(logvar[1]-b**2)\n",
    "\n",
    "        GRID_nas = torch.exp(a*xv + logmean[0]) #this is correct\n",
    "        GRID_mat = torch.exp(b*xv+c*yv + logmean[1])\n",
    "        \n",
    "        return GRID_nas,GRID_mat\n",
    "\n",
    "def get_ypred_at_RT(p,npdf,w,hyp,quantiles='PRESET',\n",
    "                   first_special=False,special_std='tail_prob',poisson_kernel = False,\n",
    "                   kernel_type='independent'):\n",
    "    p = 10**p\n",
    "    MU, VAR, STD, xmax = tr.get_moments(p)\n",
    "    \n",
    "    GRID_nas,GRID_mat = generate_grid_affine(npdf,VAR,MU,p,quantiles=quantiles)\n",
    "\n",
    "    \n",
    "   \n",
    "    xgrid_nas = torch.arange(xmax[0]+1)\n",
    "    xgrid_mat = torch.arange(xmax[1]+1)\n",
    "    \n",
    "    gammaln_xgrid_nas = lnfactorial[1:(xmax[0]+2)]\n",
    "    gammaln_xgrid_mat = lnfactorial[1:(xmax[1]+2)] \n",
    "\n",
    "    Y = torch.zeros((xmax[0]+1,xmax[1]+1))\n",
    "    if kernel_type=='correlated':\n",
    "        eps=1e-8\n",
    "        f = p[1]/(p[1]+p[2])\n",
    "        rho_ = (hyp-1)/5 #hmmm\n",
    "#         rho_ = #p[0]*np.sqrt(f*(1-f)/((1+p[0])*(1+p[0]*f)))\n",
    "        rho2 = rho_**2\n",
    "\n",
    "        a = (torch.sqrt(rho2* (GRID_nas - GRID_mat)**2 \n",
    "                + 4 * GRID_nas *  GRID_mat)/rho_\n",
    "            - GRID_nas - GRID_mat)/2\n",
    "        log_theta_mu_eps = torch.log(a + GRID_nas  + GRID_mat + eps) \n",
    "    else:\n",
    "\n",
    "        s_nas = torch.zeros((GRID_nas.shape))\n",
    "        s_mat =  torch.zeros((GRID_mat.shape))\n",
    "\n",
    "        spec = 0 if first_special else -1\n",
    "        if first_special:\n",
    "            s_nas[1:,:] = torch.diff(GRID_nas,axis=0)\n",
    "            s_mat[:,1:] = torch.diff(GRID_mat)\n",
    "        else: #last special... for now\n",
    "            s_nas[:-1,:] = torch.diff(GRID_nas,axis=0)\n",
    "            s_mat[:,:-1] = torch.diff(GRID_mat)\n",
    "\n",
    "        if special_std == 'mean':\n",
    "            s_nas[spec,:] = GRID_nas[spec,:] #not so sure about these -- need to be fixed......\n",
    "            s_mat[:,spec] = GRID_mat[:,spec]\n",
    "        elif special_std == 'neighbor': #assign_neighbor_to_special\n",
    "            s_nas[spec,:] = s_nas[1,:] if first_special else s_nas[-2,:]\n",
    "            s_mat[:,spec] = s_mat[:,1] if first_special else s_mat[:,-2]\n",
    "\n",
    "        elif special_std == 'tail_prob':\n",
    "            if first_special:\n",
    "                print('If you are using this setting, you are doing something wrong.')\n",
    "            t_max = torch.log(p[1]/p[2])/(p[1] - p[2])\n",
    "            f = (torch.exp(-p[2]*t_max) - torch.exp(-p[1]*t_max)) * p[1]/(p[1] - p[2]) * p[0]\n",
    "            tailratio = 1/(1+1/f) #the mature tail ratio\n",
    "            s_mat[:,spec] = torch.sqrt(GRID_mat[:,spec] / (1-tailratio))\n",
    "            tailratio = p[0]/(1+p[0]) #the nascent tail ratio\n",
    "            s_nas[spec,:] = torch.sqrt(GRID_nas[spec,:] / (1-tailratio))\n",
    "        elif special_std == 'tail_prob_all': #not sure this is gonna work\n",
    "            t_max = torch.log(p[1]/p[2])/(p[1] - p[2])\n",
    "            f = (torch.exp(-p[2]*t_max) - torch.exp(-p[1]*t_max)) * p[1]/(p[1] - p[2]) * p[0]\n",
    "            tailratio = 1/(1+1/f) #the mature tail ratio\n",
    "            s_mat = torch.sqrt(GRID_mat / (1-tailratio))\n",
    "            tailratio = p[0]/(1+p[0]) #the nascent tail ratio\n",
    "            s_nas = torch.sqrt(GRID_nas / (1-tailratio))\n",
    "        else:\n",
    "            print('did not specify a standard deviation convention!')\n",
    "\n",
    "        if special_std != 'tail_prob_all':\n",
    "            s_nas *= hyp\n",
    "            s_mat *= hyp\n",
    "        v_nas = s_nas**2\n",
    "        v_mat = s_mat**2\n",
    "\n",
    "        r_nas = GRID_nas**2/(v_nas-GRID_nas)\n",
    "        p_nas = 1-GRID_nas/v_nas \n",
    "        r_mat = GRID_mat**2/(v_mat-GRID_mat)\n",
    "        p_mat = 1-GRID_mat/v_mat \n",
    "\n",
    "        \n",
    "    for i in range(npdf[0]):\n",
    "        for j in range(npdf[1]):\n",
    " \n",
    "            if kernel_type == 'independent':\n",
    "                lnas = -GRID_nas[i,j] + xgrid_nas * torch.log(GRID_nas[i,j]) - gammaln_xgrid_nas\n",
    "\n",
    "                if p_nas[i,j] > 1e-10 and not poisson_kernel: #hmm doesn't seem to work\n",
    "                    lnas += torch.special.gammaln(xgrid_nas+r_nas[i,j]) - torch.special.gammaln(r_nas[i,j]) \\\n",
    "                    - xgrid_nas*torch.log(r_nas[i,j] + GRID_nas[i,j]) + GRID_nas[i,j] \\\n",
    "                    + r_nas[i,j]*torch.log(1-p_nas[i,j])\n",
    "\n",
    "                lmat =  - GRID_mat[i,j] + xgrid_mat * torch.log(GRID_mat[i,j]) - gammaln_xgrid_mat\n",
    "                if p_mat[i,j] > 1e-10 and not poisson_kernel:\n",
    "                    lmat += torch.special.gammaln(xgrid_mat+r_mat[i,j]) - torch.special.gammaln(r_mat[i,j]) \\\n",
    "                    - xgrid_mat*torch.log(r_mat[i,j] + GRID_mat[i,j]) + GRID_mat[i,j] \\\n",
    "                    + r_mat[i,j]*torch.log(1-p_mat[i,j]) #wasteful: we're recomputing a lot of stuff.\n",
    "\n",
    "\n",
    "                Y += w[i*npdf[1] + j] * torch.exp(lnas[:,None] + lmat[None,:])\n",
    "            elif kernel_type == 'correlated':\n",
    "                Z = a[i,j] * (torch.log(a[i,j] + eps) - log_theta_mu_eps[i,j]) \\\n",
    "                    + xgrid_nas[:,None] * (torch.log(GRID_nas[i,j]  + eps) - log_theta_mu_eps[i,j]) \\\n",
    "                    + xgrid_mat[None,:] * (torch.log(GRID_mat[i,j]  + eps) - log_theta_mu_eps[i,j]) \\\n",
    "                    + torch.lgamma(a[i,j] + xgrid_nas[:,None] + xgrid_mat[None,:]) \\\n",
    "                    - torch.lgamma(a[i,j]) \\\n",
    "                    - gammaln_xgrid_nas[:,None] \\\n",
    "                    - gammaln_xgrid_mat[None,:]\n",
    "                Y += w[i*npdf[1] + j] * torch.exp(Z)\n",
    "    Y[Y<1e-16]=1e-16\n",
    "#     raise\n",
    "            #print('Y shape: ',Y.shape)\n",
    "            #note convention change. Y = the predicted PMF is now returned in the same shape as the original histogram.\n",
    "            #this is fine bc Y is flattened anyway later on down the line.\n",
    "    return Y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define NORM and YPRED_FUN\n",
    "npdf = np.array([21,20])\n",
    "cheb=True\n",
    "\n",
    "if cheb:\n",
    "    n = np.arange(npdf[0])\n",
    "    q = np.flip((np.cos((2*(n+1)-1)/(2*npdf[0])*np.pi)+1)/2)\n",
    "else:\n",
    "    q = np.linspace(0,1,npdf[0]+2)[1:-1]\n",
    "    \n",
    "NORM_nas = torch.tensor(stats.norm.ppf(q))\n",
    "\n",
    "if cheb:\n",
    "    n = np.arange(npdf[1])\n",
    "    q = np.flip((np.cos((2*(n+1)-1)/(2*npdf[1])*np.pi)+1)/2)\n",
    "else:\n",
    "    q = np.linspace(0,1,npdf[1]+2)[1:-1]\n",
    "\n",
    "NORM_mat = torch.tensor(stats.norm.ppf(q))\n",
    "  \n",
    "# q = np.linspace(0,1,npdf[1]+2)[1:-1]\n",
    "# n = np.arange(npdf[1])\n",
    "# q = np.flip((np.cos((2*(n+1)-1)/(2*npdf[1])*np.pi)+1)/2)\n",
    "#     print(q)\n",
    "    \n",
    "lnfactorial = torch.special.gammaln(torch.arange(1003))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in how many training and testing files you want. Get data now also needs set size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list, test_list = tr.get_data(set_size = 256,\n",
    "                                    number_of_training_files=16,\n",
    "                                 number_of_testing_files=4,total_files=20,file_path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More useful to define this stuff in a single place.\n",
    "\n",
    "`neighbor` special_std seem to break a lot. `tail_prob` works consistently. But it's suboptimal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ypred = lambda p,npdf,w,hyp : get_ypred_at_RT(p,npdf,w,hyp,quantiles='PRESET',\\\n",
    "                                                  first_special=False,special_std='tail_prob',\\\n",
    "                                                  poisson_kernel=False,kernel_type='correlated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number: 0\n",
      "Epoch Number: 3\n",
      "Epoch Number: 4\n",
      "Epoch Number: 5\n",
      "Epoch Number: 6\n",
      "Epoch Number: 7\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "e,b,t,model = tr.train_MLP(train_list,test_list,num_epochs=10,\n",
    "                           npdf=npdf,batchsize=256,get_ypred_at_RT=get_ypred,\n",
    "                           metric='kld',learning_rate=1e-3,MLP=1)\n",
    "t2 = time.time()\n",
    "\n",
    "print(t2-t1)\n",
    "\n",
    "\n",
    "\n",
    "# IF YOU WANT TO SAVE\n",
    "#path1 = 'DEFINE/PATH/TO/STORE'\n",
    "#np.save(path1+'e_t',[e,t])\n",
    "#torch.save(model.state_dict(),'./test_MODEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we gotta start saving some of the metadata\n",
    "\n",
    "i recommend using YYMMDD format, because that's sortable whereas MMDDYY is not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'./models/220323_21x20pdf_4096params_10e_hypcorr_cheb_MODEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting!\n",
    "\n",
    "\n",
    "If you have already stored your model, load it in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-loaded model\n",
    "\n",
    "#path = './dir_03032022/'\n",
    "#npdf = [10,11]\n",
    "#model = tr.my_MLP1(3,npdf[0]*npdf[1])\n",
    "#model.load_state_dict(torch.load(path+'MODEL_kld'))\n",
    "#model.eval()\n",
    "#array = np.load(path+ 'mselog.npy',allow_pickle=True)\n",
    "#e = array[0]\n",
    "#t = array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'kld'\n",
    "\n",
    "tt.plot_training(e,t,metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n__ = 300\n",
    "\n",
    "# i know the function still says test_klds, but now it calculates whatever metric you give it\n",
    "\n",
    "metrics, metric_mean = tr.calculate_test_metrics(test_list=train_list[:n__],npdf=npdf,\n",
    "                                        model=model,get_ypred_at_RT=get_ypred,\n",
    "                                             metric = metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.plot_histogram(metrics,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.plot_CDF(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Param Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.plot_param_quantiles(metrics,train_list[:n__])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot PMFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.plot_PMF_grid(file_list=train_list[0:4],npdf=npdf,nrows=2,\n",
    "                 ncols=2,model=model,get_ypred_at_RT=get_ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PMF_grid(file_list,npdf,nrows,ncols,model,get_ypred_at_RT,kld=True,plot_points=True,log=True):\n",
    "    \n",
    "    p_list,y_list = tr.load_training_data(file_list)\n",
    "#     rand = np.zeros(nrows*ncols) \n",
    "    \n",
    "# #     print(p_list)\n",
    "#     for i in range(nrows*ncols):\n",
    "#         rand[i] = random.randint(0,len(y_list))\n",
    "    rand_inds = np.random.choice(len(y_list),nrows*ncols,replace=False)\n",
    "    y = []\n",
    "    Y = []\n",
    "    \n",
    "    for r in rand_inds:\n",
    "        r = int(r)\n",
    "        y_pred = tr.get_predicted_PMF(p_list=p_list,\n",
    "                                   npdf=npdf,position=r,model=model,get_ypred_at_RT = get_ypred_at_RT)\n",
    "        \n",
    "        y.append(y_list[r])\n",
    "        Y.append(y_pred)\n",
    "    \n",
    "    Y = [Y_.detach().numpy() for Y_ in Y]\n",
    "    y = [y_.detach().numpy() for y_ in y]\n",
    "    \n",
    "    Y = [Y_.reshape(y[i].shape) for i,Y_ in enumerate(Y)]\n",
    "\n",
    "    fig, ax1 = plt.subplots(nrows=nrows, ncols=2*ncols, figsize=(15, 15))\n",
    "    k = 0\n",
    "#     print(rand_inds)\n",
    "    j_num = np.arange(0,ncols*2,2)\n",
    "    \n",
    "    for i in range(nrows):\n",
    "        for j in j_num:\n",
    "            y_ = y[k]\n",
    "            Y_ = Y[k]\n",
    "            cm='viridis'\n",
    "            \n",
    "            vmin = np.minimum(y_.min(),Y_.min())\n",
    "            vmax = np.maximum(y_.max(),Y_.max())\n",
    "            print(vmin)\n",
    "            if log:\n",
    "                vmin = np.log10(vmin)\n",
    "                vmax = np.log10(vmax)\n",
    "                ax1[i,j].imshow(np.log10(y_).T,cmap=cm,aspect='auto',vmin=vmin,vmax=vmax)\n",
    "                ax1[i,j+1].imshow(np.log10(Y_).T,cmap=cm,aspect='auto',vmin=vmin,vmax=vmax)\n",
    "            else:\n",
    "                ax1[i,j].imshow((y_).T,cmap=cm,aspect='auto',vmin=vmin,vmax=vmax)\n",
    "                ax1[i,j+1].imshow((Y_).T,cmap=cm,aspect='auto',vmin=vmin,vmax=vmax)\n",
    "            \n",
    "            if plot_points:\n",
    "                p__ = 10**p_list[rand_inds[k]]\n",
    "                MU, VAR, STD, xmax = tr.get_moments(p__)\n",
    "                GRID_nas,GRID_mat = generate_grid_affine(npdf,VAR,MU,p__,quantiles='PRESET')\n",
    "                ax1[i,j+1].scatter(GRID_nas[:],GRID_mat[:],s=5,c='k')\n",
    "            ax1[i,j].invert_yaxis()\n",
    "            ax1[i,j].set_title('True log-PMF & basis locations')\n",
    "            ax1[i,j+1].invert_yaxis()\n",
    "            ax1[i,j+1].set_title('Reconstructed log-PMF')\n",
    "            \n",
    "            if kld == True:\n",
    "                kld_ = -np.sum(y_.flatten()*np.log(Y_.flatten()/y_.flatten()))\n",
    "                ax1[i,j].title.set_text(f'KLD: {kld_}')\n",
    "            k = k + 1\n",
    "\n",
    "        \n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it would be nice to have these plotted in a deterministic order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_PMF_grid(file_list=train_list[0:10],npdf=npdf,nrows=5,\n",
    "                 ncols=2,model=model,get_ypred_at_RT=get_ypred,log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_PMF_grid(file_list=train_list[0:10],npdf=npdf,nrows=5,\n",
    "                 ncols=2,model=model,get_ypred_at_RT=get_ypred,log=False,plot_points=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list[0:10][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fwiw it'd be even nicer to have it generate a full report every time it trains a model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, ys = tr.load_training_data(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot individual PMF\n",
    "\n",
    "p_num = 21\n",
    "\n",
    "params[p_num]\n",
    "\n",
    "tt.plot_PMF(params[p_num:p_num+1],ys[p_num],npdf,model,get_ypred_at_RT_affine,metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do : move in nnlsq code from `projects/gg220304_ml_cme_2d/learning_env.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
